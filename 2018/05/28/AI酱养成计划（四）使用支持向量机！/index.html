<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en_US">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<script src="https://me.idealli.com/images/load.gif" data-src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>



<meta name="theme-color" content="#222">


<script>
    (function(){
        if(''){
            if (prompt('这是一篇加密的文章...密码是多少呢OvO') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="机器学习,python,">








  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=5.1.2">






<meta name="description" content="也许是现成的最好的分类器">
<meta name="keywords" content="机器学习,python">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习（四）使用支持向量机！">
<meta property="og:url" content="git@github.com:creeper121386/Creeper121386.github.io.git/2018/05/28/AI酱养成计划（四）使用支持向量机！/index.html">
<meta property="og:site_name" content="WHYの小窝">
<meta property="og:description" content="也许是现成的最好的分类器">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1527170673&di=1dcc82cd28132c6c53838482d49ce094&imgtype=jpg&er=1&src=http%3A%2F%2Fs1.sinaimg.cn%2Fmw690%2F002xlA0Pgy6TFXnKcVi70%26amp%3B690">
<meta property="og:image" content="https://raw.githubusercontent.com/creeper121386/blog-file/master/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_%E9%80%89%E6%8B%A9%E5%8C%BA%E5%9F%9F_20180519150228.png">
<meta property="og:image" content="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=3799746487,1412905946&fm=27&gp=0.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/creeper121386/blog-file/master/1042406-20161128221540099-1580490663.png">
<meta property="og:updated_time" content="2020-03-23T03:34:28.744Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习（四）使用支持向量机！">
<meta name="twitter:description" content="也许是现成的最好的分类器">
<meta name="twitter:image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1527170673&di=1dcc82cd28132c6c53838482d49ce094&imgtype=jpg&er=1&src=http%3A%2F%2Fs1.sinaimg.cn%2Fmw690%2F002xlA0Pgy6TFXnKcVi70%26amp%3B690">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="git@github.com:creeper121386/Creeper121386.github.io.git/2018/05/28/AI酱养成计划（四）使用支持向量机！/">





  <title>机器学习（四）使用支持向量机！ | WHYの小窝</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?2db1eb18d81341c69d3326b3f812f6e9";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  

</head>


<body itemscope itemtype="http://schema.org/WebPage" lang="en_US">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>
   
    <a href="https://github.com/creeper121386" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WHYの小窝</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">今天也是美好的一天呢！</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="https://github.com/creeper121386" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="git@github.com:creeper121386/Creeper121386.github.io.git/2018/05/28/AI酱养成计划（四）使用支持向量机！/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="why">
      <meta itemprop="description" content>
      <meta itemprop="image" content="https://avatars2.githubusercontent.com/u/32115448?s=460&v=4">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WHYの小窝">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习（四）使用支持向量机！</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-28T18:48:17+08:00">
                2018-05-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <figure>
<img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527170673&amp;di=1dcc82cd28132c6c53838482d49ce094&amp;imgtype=jpg&amp;er=1&amp;src=http%3A%2F%2Fs1.sinaimg.cn%2Fmw690%2F002xlA0Pgy6TFXnKcVi70%26amp%3B690" alt="也许是现成的最好的分类器"><figcaption>也许是现成的最好的分类器</figcaption>
</figure>
<hr>
<a id="more"></a>
<h1 id="支持向量机svm">#4 支持向量机（SVM）</h1>
<p><strong><span class="math inline">\(\mathrm{Warning:}\)</span> 以下内容包含大量数学公式，若有不解之处，请反复阅读。</strong></p>
<h2 id="线性可分问题">线性可分问题</h2>
<p>要了解SVM的概念，让我们先从 <strong>线性可分</strong> 的问题谈起。什么是线性可分问题呢？以二分类问题为例，当一个分类器对数据集<span class="math inline">\(\Bbb D=(x_1,y_1),(x_2,y_2),...(x_n,y_n)\)</span>进行分类时，假设其中任意样本<span class="math inline">\((x_i,y_i)\)</span>的特征向量 <span class="math inline">\(x_i\)</span> 都是 <span class="math inline">\(m\)</span> 维向量，那么数据集 <span class="math inline">\(\Bbb D\)</span> 的特征就可以表示为 <span class="math inline">\(m\)</span> 维向量空间中的一组点集。进行分类的过程其实就是找到一个 *超平面** ，可以把表示两种不同类别数据的点划分成相应的两部分 <span class="math inline">\(\{C_{+1},C_{-1}\}\)</span> 。假如我们找到的超平面是线性的（例如二维空间的直线，三维空间的平面），那么这个分类问题就是线性可分问题 <img src="https://raw.githubusercontent.com/creeper121386/blog-file/master/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_%E9%80%89%E6%8B%A9%E5%8C%BA%E5%9F%9F_20180519150228.png" alt="线性分隔超平面"></p>
<p>事实上，对一个线性可分的数据集而言，这样的线性超平面不止一个。以上图中的数据为例，即使图中的直线略微左右倾斜，仍然可以正确地划分数据集。在这些不同的直线中，我们需要找的就是一条最优的直线<span class="math inline">\(L&#39;\)</span>。</p>
<p>所谓“最优”，指的是如果我我们向数据集中增添新的数据，直线仍然能很好的划分出两个类别，这就要求 $L’ $ 正好处在两个类别的数据的“正中间”，换句话说，就是要求 $ { C_{+1},C_{-1}} $ 中最靠近边界的那些点（这些点称作 <strong>支持向量点</strong> ）距离 <span class="math inline">\(L&#39;\)</span> 最近，也即间隔最大。因此最优超平面，指的也就是 <strong>最大间隔超平面</strong> 。这就将求解 <span class="math inline">\(L&#39;\)</span> 的问题转化为一个极值问题。 求解最大间隔超平面，就是支持向量机（SVM）要解决的核心问题。</p>
<h2 id="求解最大分隔超平面">求解最大分隔超平面</h2>
<h3 id="函数间隔与几何间隔">函数间隔与几何间隔</h3>
<p>假设我们要求的超平面为<span class="math inline">\(L:f(x)=w^Tx+b\)</span>（要注意这里的<span class="math inline">\(x\)</span>可能是高维向量，这取决于<span class="math inline">\(m\)</span>的值），其中<span class="math inline">\(b\)</span>是截距，<span class="math inline">\(w\)</span>是参数向量，且<span class="math inline">\(w\)</span>的方向是超平面的法矢量方向，<span class="math inline">\(x\)</span>表示点坐标（也即是特征值向量）。那么<span class="math inline">\(\Bbb D\)</span>中的任一点<span class="math inline">\(x_i\)</span>到<span class="math inline">\(L\)</span>的距离为: <span class="math display">\[d_i=\frac{|w^Tx_i+b|}{||w||}\]</span></p>
<p>由于是二分类问题，我们使用<span class="math inline">\(+1\)</span>和<span class="math inline">\(-1\)</span>来标记样本的正反类。如果分类器能够正确分类的话，对样本<span class="math inline">\((x_i,y_i)\)</span>，有:</p>
<ul>
<li>对于<span class="math inline">\(y_i=+1\)</span>，有<span class="math inline">\({w^Tx_i+b}&gt;0\)</span></li>
<li>对于<span class="math inline">\(y_i=-1\)</span>，有<span class="math inline">\({w^Tx_i+b}&lt;0\)</span></li>
</ul>
<p>也就是说，无论<span class="math inline">\(y\)</span>的取值如何，分类器能够正确分类的充要条件是：</p>
<p><span class="math display">\[y_if(x_i)=y_i(w^Tx_i+b)\geqslant0 \qquad(1)\]</span></p>
<p>令<span class="math inline">\(\gamma_i=y_if(x_i)\)</span>，<span class="math inline">\(\gamma_i\)</span>称为点<span class="math inline">\(x_i\)</span>到<span class="math inline">\(L\)</span>的函数间隔。由于<span class="math inline">\(|y|=1\)</span>，因此<span class="math inline">\(\gamma_i=|w^Tx_i+b|\)</span>，进而得出：</p>
<p><span class="math display">\[d_i=\frac{\gamma_i}{||w||}\]</span></p>
<p>（这也是为什么要把<span class="math inline">\(y\)</span>设定为<span class="math inline">\(1\)</span>和<span class="math inline">\(-1\)</span>，而不是像逻辑回归中一样设置为<span class="math inline">\(0\)</span>和<span class="math inline">\(1\)</span>的原因。） 这样就完成了表示距离的工作，接下来考虑求解超平面<span class="math inline">\(L\)</span>的最优解<span class="math inline">\(L&#39;\)</span>。</p>
<h3 id="拉格朗日算子法">拉格朗日算子法</h3>
<p>还记得我们的目的吗？我们要求的是到支持向量点的距离最近的超平面<span class="math inline">\(L&#39;\)</span>。首先我们要表示出支持向量到<span class="math inline">\(L\)</span>的距离。假设支持向量到<span class="math inline">\(L\)</span>的函数间隔为<span class="math inline">\(\gamma_v\)</span>，那么要求解的极值问题就是： <span class="math display">\[\max_{w,b} \frac{\gamma_v}{||w||},\qquad(2.1)\]</span></p>
<p><span class="math display">\[ s.t.\;\ y_i(w^Tx_i+b)\geqslant\gamma_v,\; (x_i,y_i)\in\Bbb D \qquad(3.1)\]</span></p>
<p>其中式<span class="math inline">\((2.1)\)</span>是目标函数，式<span class="math inline">\((3.1)\)</span>是限制条件。式<span class="math inline">\((2.1)\)</span>的由来是：由于<span class="math inline">\(\gamma_v\)</span>是支持向量到<span class="math inline">\(L\)</span>的函数间隔，应当是所有点到<span class="math inline">\(L\)</span>的函数间隔中最小的，因此任一点<span class="math inline">\(x_i\)</span>到<span class="math inline">\(L\)</span>的函数间隔都应当满足：</p>
<p><span class="math display">\[y_i(w^Tx_i+b)\geqslant\gamma_v\]</span></p>
<p>由于<span class="math inline">\(\gamma_v\geqslant0\)</span>，因此式<span class="math inline">\((3.1)\)</span>同时也隐含了条件<span class="math inline">\((1)\)</span>，也即保证了我们求得的<span class="math inline">\(L&#39;\)</span>是一个正确的分类器。</p>
<p>接下来对该极值问题进行简化：</p>
<ul>
<li><span class="math inline">\(w\)</span>是最终要求的变量，这里有<span class="math inline">\(\max \limits_{w,b}\frac{\gamma_v}{||w||}\iff \min \limits_{w,b}\frac{1}{2}{\gamma_v}||w||^2\)</span></li>
<li>由于<span class="math inline">\(\gamma_v\)</span>的取值并不影响最终求到的 <span class="math inline">\(L&#39;\)</span> ，因此令<span class="math inline">\(\gamma_v=1\)</span>。 （这一条可以试着自己证明一下呦！<del>才不是因为我懒哼</del>）</li>
</ul>
<p>得到简化后的极值问题： <span class="math display">\[\min_{w,b}\frac{1}{2}||w||^2,\qquad(2.2)\]</span></p>
<p><span class="math display">\[ s.t.\;\ y_i(w^Tx_i+b)\geqslant1,\; (x_i,y_i)\in\Bbb D \qquad(3.2)\]</span></p>
<p>这是一个凸二次优化问题。为了求解这类极值问题，我们可以使用<strong>拉格朗日算子法</strong>。构造拉格朗日函数： <span class="math display">\[\mathcal L(w,b,\alpha)=\frac12||w||^2+\sum_{i=1}^n \alpha_i(1-y_i(w^Tx_i+b))\]</span></p>
<p>其中<span class="math inline">\([\alpha_1,\alpha_2,...\alpha_n]\)</span>是拉格朗日算子，这里我们令<span class="math inline">\(\alpha=[\alpha_1,\alpha_2,...\alpha_n]\)</span>。拉格朗日算子法在这里有以下等式关系： <span class="math display">\[
\begin{cases}
\frac{\partial \mathcal L}{\partial w}=0 \\[2ex]
\frac{\partial \mathcal L}{\partial b}=0
\end{cases}
\;\Rightarrow\;
\begin{cases}
w=\sum_{i=1}^n\alpha_ix_iy_i \\[2ex]
0=\sum_{i=1}^n\alpha_iy_i
\end{cases}
\qquad(4.1)
\]</span></p>
<p>根据式<span class="math inline">\((4.1)\)</span>，可以消去<span class="math inline">\(w\)</span>得到<span class="math inline">\(L:f(x)=\sum_{i=1}^n\alpha_i y_i\left \langle x_i,x\right\rangle+b\)</span>，其中<span class="math inline">\(\left \langle x_i,x\right\rangle\)</span>表示向量<span class="math inline">\(x\)</span>与<span class="math inline">\(x_i\)</span>的内积。这个表达式与之前的<span class="math inline">\(L\)</span>表达式完全等价，之后就不必再考虑<span class="math inline">\(w\)</span>，只要求出最优解对应的<span class="math inline">\(\alpha\)</span>，就可以根据<span class="math inline">\((4.1)\)</span>计算得到<span class="math inline">\(w\)</span>。另一方面，注意到式<span class="math inline">\((3.2)\)</span>是不等式约束关系。在拉格朗日算子法的使用中，出现不等式约束关系时，要求必须要满足<strong>KKT条件(Karush-Kuhn-Tucker)</strong>。在这里，对应的KKT条件是：</p>
<p><span class="math display">\[
\begin{cases}
\alpha_i\geqslant0,\\[2ex]
y_if(x_i)-1\geqslant0,\qquad\qquad(5.1)\\[2ex]
\alpha_i(y_if(x_i)-1)=0.
\end{cases}
\]</span></p>
<p>可以看到，对于不同取值的<span class="math inline">\(\alpha_i\)</span>，要满足的KKT条件也不同。因此对于不同取值的<span class="math inline">\(\alpha_i\)</span>，根据式<span class="math inline">\((5.1)\)</span>可以得到：</p>
<p><span class="math display">\[
\begin{cases}
y_if(x_i)\geqslant1,\qquad\text{if }\;\alpha_i=0  \\
y_if(x_i)=1,\qquad\text{if }\;\alpha_i\gt0 
\end{cases}
\qquad(5.2)
\]</span></p>
<p>可以看到，当<span class="math inline">\(\alpha_i&gt;0\)</span>时，必有<span class="math inline">\(\gamma_i=1\)</span>，也即对应的<span class="math inline">\(x_i\)</span>必然是支持向量。事实上，<span class="math inline">\(L&#39;\)</span>的取值也仅与支持向量有关，其他数据的分布并不影响超平面的选取（这也是SVM的好处之一）。到这里我们就初步得到了求解<span class="math inline">\(L&#39;\)</span>所需要的条件，包括式<span class="math inline">\((2.2),(3.2),(4),(5.2)\)</span>。接下来只要根据这些条件求解得到<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>，就可以得到<span class="math inline">\(L&#39;\)</span>的方程。稍后，我们将对这个问题进行进一步优化，然后给出求解的详细步骤。</p>
<h3 id="软间隔与松弛变量">软间隔与松弛变量</h3>
<p>注意到，上述数学模型假设最优超平面<span class="math inline">\(L&#39;\)</span>必定可以准确无误地把 <span class="math inline">\(\{C_{+1},C_{-1}\}\)</span> 分隔开，但事实上，我们使用的训练数据中往往会有一些反常样例，这种情况下要求<span class="math inline">\(L&#39;\)</span>把所有的数据都准确地分出来是不现实的，这么强求反而可能会导致过拟合之类的问题。因此，我们可以允许少数样本点落在<span class="math inline">\(L&#39;\)</span>不属于它所在类别的另一侧。</p>
<p>为此，引入<strong>软间隔</strong>（或者称为“松弛变量”）的概念。所谓软间隔，也就是不太严格的分类器，它允许少数样本不满足约束条件<span class="math inline">\((3.2):y_i(w^Tx_i+b)\geqslant1\)</span>。为了达到这一目的，对每一个样本点<span class="math inline">\((x_i,y_i)\)</span>都引入松弛变量<span class="math inline">\(\xi_i \geqslant0\)</span>，使得对<span class="math inline">\((x_i,y_i)\)</span>的约束条件变为<span class="math inline">\(y_i(w^Tx_i+b)\geqslant1-\xi_i\)</span>，此时<span class="math inline">\(\xi_i\)</span>可以反映样本<span class="math inline">\((x_i,y_i)\)</span>允许偏离<span class="math inline">\(L&#39;\)</span>的程度。这样对于那些靠近<span class="math inline">\(L&#39;\)</span>的<del>在危险的边缘试探</del>的点，分类器就有了容错的空间。</p>
<p>当然，这些不满足约束条件的点也应当尽可能少。因此，我们在最小化目标函数<span class="math inline">\(\frac{1}{2}||w||^2\)</span>时，也应当同时最小化<span class="math inline">\(\xi\)</span>的值。为此，在目标函数中添加一项来描述各个样本的<span class="math inline">\(\xi\)</span>的总和，目标函数和约束条件就变为：</p>
<p><span class="math display">\[\min_{w,b}\frac{1}{2}||w||^2+C\sum_{i=1}^n\xi_i,\qquad(2.3)\]</span></p>
<p><span class="math display">\[ s.t.\;\ y_i(w^Tx_i+b)\geqslant1-\xi_i,\; (x_i,y_i)\in\Bbb D,\xi_i\geqslant0 \qquad(3.3)\]</span></p>
<p>其中<span class="math inline">\(C\)</span>是一个事先确定好的超参数，用于控制目标函数中的两项(“寻找间隔最大超平面”和“保证数据点偏差量最小”)之间的权重。由于目标函数和约束条件发生了变化，因此构造新的拉格朗日函数： <span class="math display">\[\mathcal L(w,b,\alpha,\mu)=\frac12||w||^2+\sum_{i=1}^n \alpha_i(1-y_i(w^Tx_i+b))-\sum_{i=1}^n\mu_i\xi_i\]</span></p>
<p>分别各个变量求偏导数，得到：</p>
<p><span class="math display">\[
\begin{cases}
\frac{\partial \mathcal L}{\partial w}=0\\[2ex]
\frac{\partial \mathcal L}{\partial b}=0\\[2ex]
\frac{\partial \mathcal L}{\partial \xi}=0
\end{cases}
\;\Rightarrow\;
\begin{cases}
w=\sum_{i=1}^n\alpha_ix_iy_i\\[2ex]
0=\sum_{i=1}^n\alpha_iy_i\\[2ex]
C=\alpha_i+\mu_i
\end{cases}
\qquad(4.2)
\]</span></p>
<p>同样的，由于约束条件是不等式，因此要满足KKT条件。此处的KKT条件为： <span class="math display">\[
\begin{cases}
\alpha_i\geqslant0,\;\mu_i\geqslant0,\\[2ex]
y_if(x_i)-1+\xi_i\geqslant0,\\[2ex]
\alpha_i(y_if(x_i)-1+\xi_i)=0,\\[2ex]
\xi_i\geqslant0,\; \mu_i\xi_i=0.
\end{cases}
\qquad(5.3)
\]</span></p>
<p>根据式<span class="math inline">\((5.3)\)</span>可以发现，当<span class="math inline">\(\alpha_i\)</span>的取值不同时，要满足的条件也不同。与之前类似，不同<span class="math inline">\(\alpha\)</span>的取值下，要满足的条件分别为：</p>
<p><span class="math display">\[
\begin{cases}
y_if(x_i)\geqslant1,\qquad\text{if }\;\alpha_i=0  \\
y_if(x_i)=1,\qquad\text{if }\;0&lt;\alpha_i&lt;C \\
y_if(x_i)\leqslant1,\qquad\text{if }\;\alpha_i&gt;C 
\end{cases}
\qquad(5.4)
\]</span></p>
<p><span class="math inline">\(\alpha\)</span>在不同条件下，相应的<span class="math inline">\(x_i,y_i\)</span>要满足不同的关系。从这里也可以看到，<span class="math inline">\(\alpha_i\)</span>和<span class="math inline">\((x_i,y_i)\)</span>是一一对应的。</p>
<h2 id="核函数">核函数</h2>
<h3 id="映射到高维空间">映射到高维空间</h3>
<p>还记得我们一直讨论的是线性可分问题吗？之前的内容都是针对线性可分问题而言的。但是在实际的数据处理中，数据分布往往不是线性可分的（例如典型的 <strong>“异或问题”</strong> ）。这种情况下我们无法通过一个线性超平面来分隔数据。</p>
<p>对于线性不可分问题，不同的机器学习算法有不同的处理方法。而SVM的处理方法是：使用一个映射函数<span class="math inline">\(\phi\)</span>，把原数据映射到某一个更高维的特征空间，使得在这个空间中，数据变得线性可分。（事实上，必定存在某个维度，使得映射后的数据线性可分。）以下图为例，一组线性不可分的二维数据经过某种变换<span class="math inline">\(\phi\)</span>映射到三维空间，在新的特征空间中，数据变得线性可分。之后，只要在新的特征空间中列出相应的拉格朗日方程，求解极值问题即可得到<span class="math inline">\(L&#39;\)</span>。 <img src="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=3799746487,1412905946&amp;fm=27&amp;gp=0.jpg" alt="使用核函数映射到高维空间"></p>
<p>我们之前在极值问题中得到过消去<span class="math inline">\(w\)</span>，使用<span class="math inline">\(\alpha\)</span>表达的<span class="math inline">\(L\)</span>的方程：<span class="math inline">\(f(x)=\sum_{i=1}^n\alpha_i y_i\left \langle x_i,x\right\rangle+b\)</span>。在数据映射到高维空间后，方程变为： <span class="math display">\[f(x)=\sum_{i=1}^n\alpha_i y_i\left \langle \phi x_i,\phi x\right\rangle+b\qquad(6)\]</span></p>
<p>其中<span class="math inline">\(\phi x_i,\phi x\)</span>是映射后的特征向量和自变量。可以看到，其中涉及到了<span class="math inline">\(\phi x_i\)</span>和<span class="math inline">\(\phi x\)</span>内积的计算，也即是矩阵的乘法计算。这就面临一个问题：如果映射之后的特征空间维度很高，那么进行矩阵计算将会相当耗时。为了解决这一问题，我们使用核函数的方法。</p>
<h3 id="核方法">核方法</h3>
<p>核方法的思想是：为了避免在高维空间中进行矩阵运算，那么在原空间中是否可以找到这么一个函数<span class="math inline">\(k(x_i,x)\)</span>，使得<span class="math inline">\(k(x_i,x)\)</span>恰好等于高维空间中<span class="math inline">\(\left \langle x_i,x\right\rangle\)</span>的值呢？如果函数<span class="math inline">\(k(\dot\;,\dot\;)\)</span>存在的话，就可以直接在低维空间中计算内积，不必计算高维向量的乘法了。这样的函数<span class="math inline">\(k\)</span>就称为<strong>核函数</strong>。</p>
<p><span class="math inline">\(k\)</span>的确是存在的，而且还不止一种。假设有核函数<span class="math inline">\(k(\dot\;,\dot\;)\)</span>，那么定义核矩阵<span class="math inline">\(K\)</span>： <span class="math display">\[
K=
  \begin{pmatrix}
   k(x_1,x_1) &amp;  \cdots &amp; k(x_1,x_n)\\[2ex]
  \vdots &amp; \ddots &amp; \vdots \\
   k(x_j,x_1)  &amp; \cdots &amp; k(x_j,x_n)  \\[2ex]
   \vdots &amp; \ddots &amp; \vdots \\
   k(x_n,x_1)  &amp; \cdots &amp; k(x_n,x_n)  \\
  \end{pmatrix}
\]</span></p>
<p>可以证明，如果对于任意的数据集<span class="math inline">\(D\)</span>而言，<span class="math inline">\(K\)</span>都是半正定矩阵，那么<span class="math inline">\(k(\dot\;,\dot\;)\)</span>就可以作为核函数。此外，两个核函数的线性组合、两个核函数的直积也是核函数。下面给出一些常用的核函数：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">函数名称</th>
<th style="text-align: center;">表达式</th>
<th style="text-align: center;">参数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">线性核</td>
<td style="text-align: center;"><span class="math inline">\(k(x,y)=x^Ty\)</span></td>
<td style="text-align: center;"><span class="math inline">\(None\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">多项式核</td>
<td style="text-align: center;"><span class="math inline">\(k(x,y)=(x^Ty)^d\)</span></td>
<td style="text-align: center;"><span class="math inline">\(d\geqslant1\)</span>，是多项式的次数</td>
</tr>
<tr class="odd">
<td style="text-align: center;">高斯核</td>
<td style="text-align: center;"><span class="math inline">\(k(x,y)=exp(-\frac{\|x-y\|^2}{2\sigma^2})\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\sigma&gt;0\)</span>，是高斯核的带宽</td>
</tr>
<tr class="even">
<td style="text-align: center;">拉普拉斯核</td>
<td style="text-align: center;"><span class="math inline">\(k(x,y)=exp(-\frac{\|x-y\|}{\sigma})\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\sigma&gt;0\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Sigmoid核</td>
<td style="text-align: center;"><span class="math inline">\(k(x,y)=tanh(\beta x^Ty+\theta)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(tanh:\)</span>双曲正切函数，<span class="math inline">\(\beta&gt;0,0&gt;\theta\)</span></td>
</tr>
</tbody>
</table>
<p>上述函数都满足核函数的条件，也即<span class="math inline">\(k(x_i,x)=\left \langle x_i,x\right\rangle\)</span>。使用核函数的好处在于，当我们在低维空间中使用特定的核函数<span class="math inline">\(k\)</span>时，就已经隐式地把数据映射到了某一个高维空间中去了，不必再进行复杂的映射变换，也无需关注映射后的数据是怎样分布的。如果使用不同的核函数，就可以把数据映射到不同的高维特征空间。因此，核函数的选取也就成为了影响SVM性能的一个重要因素。</p>
<p>进行核函数映射之后，极值问题中所有涉及到向量内积的计算，就可以全部用核函数代替（换言之，只要用核函数代替内积，就相当于完成了高维映射），接下来，就可以进行对极值问题的具体求解了。</p>
<h2 id="训练模型序列最小化优化算法smo">训练模型：序列最小化优化算法(SMO)</h2>
<h3 id="对偶问题">对偶问题</h3>
<p>接下来，我们就要对这个复杂的极值问题就行求解了。首先再次梳理该极值问题的条件。我们要求的目标函数和约束条件分别为： <span class="math display">\[\min_{w,b}\frac{1}{2}||w||^2+C\sum_{i=1}^n\xi_i,\qquad(2.3)\]</span></p>
<p><span class="math display">\[ s.t.\;\ y_i(w^Tx_i+b)\geqslant1-\xi_i,\; (x_i,y_i)\in\Bbb D,\xi_i\geqslant0 \qquad(3.3)\]</span></p>
<p>由该问题构造拉格朗日函数并对各项求偏导数，以及求出相应的KKT条件，再进行相应化简和推导，这些条件综合起来，得到的是式<span class="math inline">\((4.2),(5.4)\)</span>：</p>
<p><span class="math display">\[
\begin{cases}
w=\sum_{i=1}^n\alpha_ix_iy_i\\
0=\sum_{i=1}^n\alpha_iy_i\\
C=\alpha_i+\mu_i
\end{cases}(4.2)\quad\&amp;\quad
\begin{cases}
y_if(x_i)\geqslant1,\quad\text{if }\;\alpha_i=0  \\
y_if(x_i)=1,\quad\text{if }\;0&lt;\alpha_i&lt;C \\
y_if(x_i)\leqslant1,\quad\text{if }\;\alpha_i&gt;C 
\end{cases}
\quad(5.4)
\]</span></p>
<p>并且由于引入了核函数，消去<span class="math inline">\(w\)</span>，得到用<span class="math inline">\(\alpha\)</span>表示的超平面<span class="math inline">\(L\)</span>表达式为： <span class="math display">\[f(x)=\sum_{i=1}^n\alpha_i y_ik(x_i,x)+b\qquad(6)\]</span></p>
<p>这就是我们得到的所有条件。将式<span class="math inline">\((4.2)\)</span>代入<span class="math inline">\((2.3)\)</span>，可以消去<span class="math inline">\(w,b\)</span>,得到该极值问题的对偶问题： <span class="math display">\[\max_{\alpha}\sum_{i=1}^n\alpha_i-\frac12 \sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_jk(x_i,x_j),\qquad(2.4)\]</span></p>
<p><span class="math display">\[ s.t.\sum_{i=1}^n\alpha_iy_i=0,\; (x_i,y_i)\in\Bbb D,\;0\leqslant\alpha\leqslant C \qquad(3.4)\]</span></p>
<p>该问题和原来的极值问题完全等价。同时，根据已有条件也可以得到<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>关于<span class="math inline">\(\alpha\)</span>的表达式： <span class="math display">\[
\begin{cases}
w=\sum_{i=1}^n\alpha_ix_iy_i \\[2ex]
b=\frac{1}{|\Bbb S|}\sum_{i=1}^{|\Bbb S|}\left( y_i-\sum_{i=1}^{|\Bbb S|}\alpha_iy_ik(x_i,x_j)\right)
\end{cases}
\qquad(7)
\]</span></p>
<p>其中，<span class="math inline">\(\Bbb S\)</span>表示所有支持向量的集合。<span class="math inline">\(b\)</span>表达式的由来是：对任意支持变量，都有<span class="math inline">\(y_if(x_i)=1\)</span>成立，因此根据该式求出一个<span class="math inline">\(b_i\)</span>，然后对所有支持变量求得的<span class="math inline">\(b_i\)</span>求和并取平均值。可以看到，在对偶问题中，只有向量<span class="math inline">\(\alpha\)</span>一个变量，因此只要求出<span class="math inline">\(\alpha\)</span>，就可以根据式<span class="math inline">\((7)\)</span>得到<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>，进而求出最优超平面<span class="math inline">\(L&#39;\)</span>。</p>
<h3 id="求解alpha">求解<span class="math inline">\(\alpha\)</span></h3>
<p>接下来我们就要开始求解对偶问题<span class="math inline">\((2.4),(3.4)\)</span>了。事实上，这个问题是一个凸二次规划问题，有许多现成的算法库可以调用。但是，直接求解这个问题会十分复杂——我们使用的训练数据量有时候会很大。因此我们需要一种简便的优化算法来求<span class="math inline">\(\alpha\)</span>的值，这个算法就是<strong>序列最小化优化算法(SMO)</strong>（其实梯度下降法也可以呦(。・・)ノ）。</p>
<p>SMO算法的思想是，不直接去求解这个二次规划问题，而是先将向量<span class="math inline">\(\alpha\)</span>初始化，然后然后再通过不断迭代，使得目标函数的值不断增大，最终逼近最大值。每一次迭代中，都只把<span class="math inline">\(\alpha\)</span>的其中两个元素<span class="math inline">\(\alpha_i,\alpha_j\)</span>视作变量，其他的<span class="math inline">\(\alpha\)</span>视作常数，只优化这两个<span class="math inline">\(\alpha\)</span>。具体的迭代步骤是：</p>
<ul>
<li>首先初始化<span class="math inline">\(\alpha=[\alpha_1,\alpha_2...\alpha_n]=[0,0,0...0]\)</span></li>
<li>在<span class="math inline">\(\alpha\)</span>的<span class="math inline">\(n\)</span>个元素中一选择一个<span class="math inline">\(\alpha_i\)</span>作为第一个迭代对象（要怎么选呢？稍后会谈到）</li>
<li>在剩下的<span class="math inline">\(n-1\)</span>个元素中选择一个<span class="math inline">\(\alpha_j\)</span>作为第二个迭代对象（要怎么选呢？稍后会谈到）</li>
<li>暂且不管其他<span class="math inline">\(\alpha\)</span>，根据已知条件求解得到<span class="math inline">\(\alpha_i,\alpha_j\)</span>的值</li>
<li>选取两个新的<span class="math inline">\(\alpha\)</span>继续进行迭代，直到所有<span class="math inline">\(\alpha\)</span>都更新完毕</li>
</ul>
<p>SMO算法看起来似乎比直接求解优化问题要更麻烦——AI酱可不这么认为o(￣ヘ￣o＃)！事实上SMO算法得益于可以快速收敛的优点，成为了SVM中的经典算法。SMO算法每次只选择两个<span class="math inline">\(\alpha\)</span>进行更新，因此将多变量的优化问题变成了单变量优化问题（没错，虽然有两个<span class="math inline">\(\alpha\)</span>但它的确是个单变量问题！稍后你就会看到这两个<span class="math inline">\(\alpha\)</span>之间是有等式关系的），这样极大降低了优化问题的计算难度。SMO算法只要迭代进行单变量二次优化问题的求解，直到满足停止条件，就可以得到所有的<span class="math inline">\(\alpha\)</span>值。</p>
<p>接下来以其中一次迭代为例，给出求<span class="math inline">\(\alpha_i\)</span>和<span class="math inline">\(\alpha_j\)</span>的步骤：</p>
<h3 id="启发式方法">启发式方法</h3>
<p>首先你会好奇，为什么每次要选择两个变量<span class="math inline">\(\alpha\)</span>进行优化呢？一个不阔以吗？是的当然不阔以ヽ（≧^≦）ノ！我们要求优化之后的<span class="math inline">\(\alpha\)</span>都满足约束条件<span class="math inline">\((4.2),(5.4)\)</span>，其中有一条： <span class="math display">\[0=\sum_{i=1}^n\alpha_iy_i\]</span></p>
<p>如果每次都只针对一个<span class="math inline">\(\alpha\)</span>进行优化的话，无论如何也无法保证每次选取的<span class="math inline">\(\alpha\)</span>之间都满足这个条件。因此，每次选择两个<span class="math inline">\(\alpha\)</span>（假设用<span class="math inline">\(\alpha_1\)</span>表示第一个优化对象，<span class="math inline">\(\alpha_2\)</span>表示第二个优化对象），只要保证<span class="math inline">\(y_1\alpha_1+y_2\alpha=\varsigma\)</span>，其中<span class="math inline">\(\varsigma\)</span>是一个常数，就可以使得<span class="math inline">\(0=\sum_{i=1}^n\alpha_iy_i\)</span>成立。</p>
<p>那么，在每一次迭代之前，要选择哪两个变量作为<span class="math inline">\(\alpha_1,\alpha_2\)</span>呢？我们当然可以随机地进行选择，但我们总希望先选出当前情况下使得优化之后<strong>效果最好</strong>的两个变量，为此，我们采用<strong>启发式</strong>的选取方法。</p>
<p>首先回忆一下 <strong>支持向量</strong>的概念。之前曾经提到，超平面<span class="math inline">\(L&#39;\)</span>的表达式事实上只和支持向量有关。因此，优化支持向量<span class="math inline">\(x_i\)</span>对应的<span class="math inline">\(\alpha_i\)</span>带来的收益更大；而如果优化其他点对应的<span class="math inline">\(\alpha\)</span>，带来的收益就小很多。我们知道，对支持变量<span class="math inline">\(x_i\)</span>，有<span class="math inline">\(y_if(x_i)=1\)</span>，而根据式<span class="math inline">\((5.4)\)</span>，有： <span class="math display">\[y_if(x_i)=1,\quad\text{if }\;0&lt;\alpha_i&lt;C\]</span></p>
<p>也就是说，当<span class="math inline">\(\alpha\)</span>的取值在<span class="math inline">\((0,C)\)</span>之间时，对应的数据点是支持向量。因此，对于<span class="math inline">\(\alpha_1,\alpha_2\)</span>的选取，都应当优先在<span class="math inline">\((0,C)\)</span>中选取，如果找不到<span class="math inline">\((0,C)\)</span>中的<span class="math inline">\(\alpha\)</span>，再从其他区间选择。</p>
<p>对于<span class="math inline">\(\alpha_1\)</span>和<span class="math inline">\(\alpha_2\)</span>的选择，也要使用不同的方法。接下来进行分别讨论：</p>
<h4 id="alpha_1的选择"><span class="math inline">\(\alpha_1\)</span>的选择</h4>
<p>我们为所有的<span class="math inline">\(\alpha\)</span>都赋予了初值<span class="math inline">\(0\)</span>，SMO算法的目的是通过优化<span class="math inline">\(\alpha\)</span>使得最终所有的<span class="math inline">\(\alpha\)</span>都满足约束条件，并且在满足约束条件的前提下，使得目标函数最大。因此，我们只需要选择<strong>违背约束条件最严重</strong>的变量<span class="math inline">\(\alpha_i\)</span>作为<span class="math inline">\(\alpha_1\)</span>，并使得它在优化之后满足约束条件，那么就可以认为，优化这个<span class="math inline">\(\alpha_i\)</span>的效果最好，或者说…优化程度最高（这有些类似梯度下降的做法）。</p>
<p><span class="math inline">\(\alpha\)</span>要满足的条件之前已经给出了(式<span class="math inline">\((4.2,(5.4)\)</span>)，其中：</p>
<ul>
<li><span class="math inline">\((4.2)\)</span>是优化过程中要用到的条件，以及<span class="math inline">\(w\)</span>和<span class="math inline">\(\alpha\)</span>的关系，在这里无法作为判断依据；</li>
<li><span class="math inline">\((5.4)\)</span>是KKT条件，是关于<span class="math inline">\(\alpha\)</span>的不等式约束条件，可以作为判断依据。因此，我们要选取的就是<strong>违反KKT条件最严重</strong>的变量<span class="math inline">\(\alpha\)</span>作为<span class="math inline">\(\alpha_1\)</span>。</li>
</ul>
<p>衡量<span class="math inline">\(\alpha\)</span>违反KKT条件的程度也很简单，例如对于<span class="math inline">\(\alpha_i\in(0,C)\)</span>，要求<span class="math inline">\(y_if(x_i)=1\)</span>，因此只要使得<span class="math inline">\(y_if(x_i)\)</span>和<span class="math inline">\(1\)</span>之间的距离最大就可以啦。据此，得出<span class="math inline">\(\alpha_1\)</span>的选取方法：</p>
<p><span class="math display">\[
\alpha_1=
\begin{cases}
\mathop{argmax}_{\alpha_i} \;1-y_if(x_i),\quad\text{if }\;\alpha_i=0  \\
\mathop{argmax}_{\alpha_i} \;|y_if(x_i)-1|,\quad\text{if }\;0&lt;\alpha_i&lt;C \\
\mathop{argmax}_{\alpha_i} \;y_if(x_i)-1,\quad\text{if }\;\alpha_i&gt;C 
\end{cases}
\qquad(8)
\]</span></p>
<p>在这三种情况中，我们又比较优先选择情况2（因为恰好是支持向量对应的<span class="math inline">\(\alpha\)</span>），这样，就可以选出每一轮迭代的<span class="math inline">\(\alpha_1\)</span>。</p>
<h3 id="alpha_2的选择"><span class="math inline">\(\alpha_2\)</span>的选择</h3>
<p>选取得到<span class="math inline">\(\alpha_1\)</span>之后，根据<span class="math inline">\(\alpha_1\)</span>来选取<span class="math inline">\(\alpha_2\)</span>。因为要优化的<span class="math inline">\(\alpha_1\)</span>已经固定，我们只要选择使得优化收益最大的<span class="math inline">\(\alpha_2\)</span>（也即使得目标函数上升最快的一个<span class="math inline">\(\alpha\)</span>）就可以了。此时，这个问题就变成了一个单变量优化问题。</p>
<p>稍后我们进行的具体优化步骤会保证我们向着使得目标函数增长最快的方向优化<span class="math inline">\(\alpha_1\)</span>和<span class="math inline">\(\alpha_2\)</span>，因此选取<span class="math inline">\(\alpha_2\)</span>时不必担心优化后目标函数不增反降，只要使得优化之后<span class="math inline">\(\alpha_1\)</span>和<span class="math inline">\(\alpha_2\)</span>的改变<strong>尽可能大</strong>就可以了。因此引入一个判断标准<span class="math inline">\(E\)</span>。对样本<span class="math inline">\((x_i,y_i)\)</span>: <span class="math display">\[E_i=\underbrace{\sum_{i=1}^n\alpha_i y_ik(x_i,x_i)+b}_{f(x_i)}-y_i\]</span></p>
<p>当<span class="math inline">\(\alpha_j\)</span>对应的<span class="math inline">\(|E_1-E_j|\)</span>最大时，就能使得优化之后的变量<span class="math inline">\(\alpha\)</span>改变最大，此时<span class="math inline">\(\alpha_j\)</span>就是我们要选择的<span class="math inline">\(\alpha_2\)</span>。也即： <span class="math display">\[\alpha_2=argmax_{\alpha_j}\; |E_1-E_j|\]</span></p>
<p>这样就完成了待优化参数<span class="math inline">\(\alpha\)</span>的选择。选择<span class="math inline">\(\alpha\)</span>的python代码如下所示： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseAlpha</span><span class="params">(trainData, trainLabel, b, alpha, index)</span>:</span></span><br><span class="line">    E = <span class="number">0</span></span><br><span class="line">    num = len(index)</span><br><span class="line">    predLst = [pred(trainData[x], b, alpha, kernel,</span><br><span class="line">                    trainData, trainLabel) <span class="keyword">for</span> x <span class="keyword">in</span> index]</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(num):</span><br><span class="line">        ix = index[x]</span><br><span class="line">        <span class="keyword">if</span> alpha[ix] &gt; <span class="number">0</span> <span class="keyword">and</span> alpha[ix] &lt; C:</span><br><span class="line">            preE = E</span><br><span class="line">            E = max(E, np.abs(<span class="number">1</span>-predLst[x]*trainLabel[ix]))</span><br><span class="line">            <span class="keyword">if</span> preE != E:</span><br><span class="line">                i = x</span><br><span class="line">    <span class="keyword">if</span> E == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(num):</span><br><span class="line">            ix = index[x]</span><br><span class="line">            preE = E</span><br><span class="line">            <span class="keyword">if</span> alpha[ix] == <span class="number">0</span>:</span><br><span class="line">                E = max(E, <span class="number">1</span>-predLst[x]*trainLabel[ix])</span><br><span class="line">            <span class="keyword">elif</span> alpha[ix] == C:</span><br><span class="line">                E = max(E, predLst[x]*trainLabel[ix]<span class="number">-1</span>)</span><br><span class="line">            <span class="keyword">if</span> preE != E:</span><br><span class="line">                i = x</span><br><span class="line">    <span class="keyword">if</span> E == <span class="number">0</span>:</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">    E = [predLst[x]-trainLabel[index[x]] <span class="keyword">for</span> x <span class="keyword">in</span> range(num)]</span><br><span class="line">    j = np.argmax(np.abs(np.array(E) - E[i]))</span><br><span class="line">    i = index[i]</span><br><span class="line">    j = index[j]</span><br><span class="line">    <span class="keyword">return</span> i, j</span><br></pre></td></tr></table></figure></p>
<h3 id="优化alpha_i和alpha_j">优化<span class="math inline">\(\alpha_i\)</span>和<span class="math inline">\(\alpha_j\)</span></h3>
<p>接下来就可以对<span class="math inline">\(\alpha_i\)</span>和<span class="math inline">\(\alpha_j\)</span>进行优化了。首先根据条件<span class="math inline">\((4.2)\)</span>，得到<span class="math inline">\(\alpha_i,\alpha_j\)</span>之间的关系式：</p>
<p><span class="math display">\[y_1\alpha_1^{old}+y_2\alpha_2^{old}=y_1\alpha_1^{new}+y_2\alpha_2^{new}=\varsigma\qquad(9.1)\]</span></p>
<p>其中<span class="math inline">\(\alpha_1^{old}\)</span>和<span class="math inline">\(\alpha_2^{old}\)</span>已知，要求的是<span class="math inline">\(\alpha_1^{new},\alpha_2^{new}\)</span>，我们就可以将<span class="math inline">\(\alpha_1^{new}\)</span>用<span class="math inline">\(\alpha_2^{new}\)</span>表示（当然反过来也是可以的），只要求出<span class="math inline">\(\alpha_2^{new}\)</span>就解决了对<span class="math inline">\(\alpha\)</span>的优化问题。由于<span class="math inline">\(y\)</span>的值只能是<span class="math inline">\(\pm 1\)</span>，所以根据<span class="math inline">\(y_1,y_2\)</span>的正负情况，上述条件变成：</p>
<p><span class="math display">\[
\begin{cases}
\alpha_1^{new}=-\alpha_2^{new}+\alpha_1^{old}+\alpha_2^{old} ,\quad if\ y_1=y_2\\
\alpha_1^{new}=\alpha_2^{new}+\alpha_1^{old}-\alpha_2^{old}
,\quad if\ y_1\ne y_2
\end{cases}
\qquad(9.2)
\]</span></p>
<p>可以认为<span class="math inline">\(\alpha_1^{new}\)</span>和<span class="math inline">\(\alpha_2^{new}\)</span>是一次函数关系。对应上述两种情况，<span class="math inline">\(\alpha_2^{new}\)</span>与<span class="math inline">\(\alpha_1^{new}\)</span>之间的函数关系可以用图形表示为：</p>
<p><img src="https://raw.githubusercontent.com/creeper121386/blog-file/master/1042406-20161128221540099-1580490663.png"></p>
<p>上图中的<span class="math inline">\(\alpha\)</span>之所以落在<span class="math inline">\([0,C]\)</span>的盒子内，是因为我们之前选取的<span class="math inline">\(\alpha_1,\alpha_2\)</span>都是优先从<span class="math inline">\([0,C]\)</span>区间内选取的。根据图像可以看出，由于<span class="math inline">\(\alpha_1^{new},\alpha_2^{new}\)</span>之间的约束关系<span class="math inline">\((9.2)\)</span>，使得<span class="math inline">\(\alpha_2^{new}\)</span>是有上下界的。假设<span class="math inline">\(\alpha_2^{new}\)</span>的上下界分别为<span class="math inline">\(H,L\)</span>，根据图像有：</p>
<p><span class="math display">\[
\begin{cases}
L=max(0,\alpha_2^{old}-\alpha_1^{old}),H=min(C,C+\alpha_2^{old}-\alpha_1^{old})\quad if\ y_1\ne y_2\\
L=max(0,\alpha_2^{old}+\alpha_1^{old}-C),H=min(C,\alpha_2^{old}+\alpha_1^{old})\quad if\ y_1=y_2\\
\end{cases}
\]</span></p>
<p>因此，稍后我们求出<span class="math inline">\(\alpha_2^{new}\)</span>之后，还要对其进行 <strong>剪切</strong>：如果<span class="math inline">\(\alpha_2^{new}\)</span>的值不在<span class="math inline">\([L,H]\)</span>之间，需要把多余部分剪掉，即：</p>
<p><span class="math display">\[
\alpha_2^{new}=
\begin{cases}
H\qquad if\ \alpha_2^{new}&gt;H \\
\alpha_2^{new} \quad if\ \alpha_2^{new}\in [L,H]\\
L \qquad if\ \alpha_2^{new}&lt;L
\end{cases}
\]</span></p>
<p>这样得到的就是最终的<span class="math inline">\(\alpha_2^{new}\)</span>。</p>
<h3 id="求解alpha_2newalpha_1new">求解<span class="math inline">\(\alpha_2^{new},\alpha_1^{new}\)</span></h3>
<p>此刻，我们已经将最初的优化问题变成了仅与<span class="math inline">\(\alpha_2^{new}\)</span>有关的单变量优化问题。事实上，这个优化问题就是一个简单的二次函数求最值问题，只不过目标函数稍微复杂一些。经过漫长的推导（真的很漫长…），就可以得到最终的只含有<span class="math inline">\(\alpha_2^{new}\)</span>的目标函数，接下来求出目标函数在<span class="math inline">\(\alpha_2^{new}\)</span>处的梯度，然后找到梯度为<span class="math inline">\(0\)</span>的点，就可以使得目标函数<span class="math inline">\((2.4)\)</span>最大，得到<span class="math inline">\(\alpha_2^{new}\)</span>的值。最终导出的方程式是：</p>
<p><span class="math display">\[(k(x_1,x_1) +k(x_2,x_2)-2k(x_1,x_2))\alpha_2^{new} = y_2((k(x_1,x_1) +k(x_2,x_2)-2k(x_1,x_2))\alpha_2^{old}y_2 +y_2-y_1 +g(x_1) - g(x_2))\]</span></p>
<p><span class="math display">\[\;\;\;\qquad \qquad = (k(x_1,x_1) +k(x_2,x_2)-2k(x_1,x_2)) \alpha_2^{old} + y2(E_1-E_2)\]</span></p>
<p>要注意，其中<span class="math inline">\(x_1,x_2\)</span>表示的是<span class="math inline">\(\alpha_1,\alpha_2\)</span>对应的<span class="math inline">\(x\)</span>，<span class="math inline">\(E_1,E_2\)</span>与之前提到的<span class="math inline">\(E_i\)</span>计算方法一致。由上式可以得出更新<span class="math inline">\(\alpha_2^{new}\)</span>的表达式：</p>
<p><span class="math display">\[\alpha_2^{new,unc} = \alpha_2^{old} + \frac{y2(E_1-E_2)}{k(x_1,x_1) +k(x_2,x_2)-2k(x_1,x_2))}\]</span></p>
<p>得到<span class="math inline">\(\alpha_2^{new}\)</span>，就可以根据式<span class="math inline">\((9.2)\)</span>求出<span class="math inline">\(\alpha_1^{new}\)</span>，这样，第一轮选择出来的<span class="math inline">\(\alpha_1,\alpha_2\)</span>就优化完毕了。接下来只要循环这个过程，直到所有的<span class="math inline">\(\alpha\)</span>都被更新。得到更新后的<span class="math inline">\(\alpha\)</span>之后，只要根据式<span class="math inline">\((7)\)</span>，就可以得到<span class="math inline">\(w,b\)</span>，进而得到最优超平面 $ L ^* $ ，这样就完成了SVM分类器。</p>
<p>接下来给出使用SMO算法进行训练的python代码（注意：以下代码封装的是一个连贯的函数，请连起来看0v0）。首先确定要使用的核函数，并将所有的<span class="math inline">\(\alpha\)</span>值初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(trainData, trainLabel, num, kernel)</span>:</span></span><br><span class="line">    <span class="comment"># alpha = np.random.randint(0, C, (num, ))</span></span><br><span class="line">    print(<span class="string">'*** data training start ***'</span>)</span><br><span class="line">    func = K[kernel] <span class="keyword">if</span> kernel <span class="keyword">else</span> np.dot</span><br><span class="line">    alpha = np.zeros(num)</span><br></pre></td></tr></table></figure>
<p>接下来开始循环选取适当的<span class="math inline">\(\alpha_i,\alpha_j\)</span>进行优化，选取方法是直接调用之前的<code>chooseAlpha</code>函数。选取完毕后，首先计算出对应的<span class="math inline">\(E_i,E_j\)</span>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(loopTimes):</span><br><span class="line">    index = [x <span class="keyword">for</span> x <span class="keyword">in</span> range(num)]</span><br><span class="line">    b = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> len(index):</span><br><span class="line">        i, j = chooseAlpha(trainData, trainLabel, b, alpha, index)</span><br><span class="line">        Ei = pred(trainData[i], b, alpha, kernel,</span><br><span class="line">                  trainData, trainLabel)-trainLabel[i]</span><br><span class="line">        Ej = pred(trainData[j], b, alpha, kernel,</span><br><span class="line">                  trainData, trainLabel)-trainLabel[j]</span><br></pre></td></tr></table></figure></p>
<p>接下来根据之前的内容，计算得出<span class="math inline">\(\alpha_2^{new}\)</span>的临时解（未进行剪切）： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">preI = alpha[i].copy()</span><br><span class="line">preJ = alpha[j].copy()</span><br><span class="line">yi = trainLabel[i]</span><br><span class="line">yj = trainLabel[j]</span><br><span class="line">xi = trainData[i]</span><br><span class="line">xj = trainData[j]</span><br><span class="line"><span class="keyword">if</span> yi == yj:</span><br><span class="line">    L = max(<span class="number">0</span>, alpha[j]+alpha[i]-C)</span><br><span class="line">    H = min(C, alpha[j]+alpha[i])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    L = max(<span class="number">0</span>, alpha[j]-alpha[i])</span><br><span class="line">    H = min(C, C+alpha[j]-alpha[i])</span><br><span class="line"><span class="comment"># c = -sum([trainLabel[k]*alpha[k]</span></span><br><span class="line"><span class="comment">#          for k in range(num) if k != i and k != j])</span></span><br><span class="line">eta = <span class="number">2</span>*func(xi, xj.T)-func(xi, xi.T)-func(xj, xj.T)</span><br></pre></td></tr></table></figure></p>
<p>如果求得的上下界相等，或者得到的<span class="math inline">\(\alpha_2^{new}\)</span>与原值几乎相等（无需更新），则直接跳过本轮循环。否则，对<span class="math inline">\(\alpha_2^{new}\)</span>进行剪切，求出<span class="math inline">\(\alpha_2^{new}\)</span>的解析解： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> L != H <span class="keyword">and</span> eta &lt; <span class="number">0</span>:</span><br><span class="line">    alpha[j] -= yj * (Ei-Ej)/eta</span><br><span class="line">    <span class="keyword">if</span> alpha[j] &gt; H:</span><br><span class="line">        alpha[j] = H</span><br><span class="line">    <span class="keyword">if</span> alpha[j] &lt; L:</span><br><span class="line">        alpha[j] = L</span><br><span class="line">    <span class="keyword">if</span> np.abs(alpha[j]-preJ) &lt; <span class="number">1e-3</span>:</span><br><span class="line">        index.remove(i)</span><br><span class="line">        <span class="keyword">continue</span></span><br></pre></td></tr></table></figure></p>
<p>接下来对<span class="math inline">\(\alpha_1\)</span>进行更新，并根据式<span class="math inline">\((7)\)</span>计算<span class="math inline">\(b\)</span>。如果当前更新的样本点是支持向量点，则求出<span class="math inline">\(b\)</span>在本轮循环的平均值。最后从索引列表中删除当前<span class="math inline">\(\alpha_i,\alpha_j\)</span>对应的索引，表示该索引对应的数据已经更新完毕。不断循环该过程，就可以完成训练，最终返回更新后的<span class="math inline">\(\alpha,b\)</span>，训练结束。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">            alpha[i] += yi*yj*(preJ-alpha[j])</span><br><span class="line">            b1 = b-Ei-yi*(alpha[i]-preI)*func(xi, xi.T) -\</span><br><span class="line">                yj*(alpha[j]-preJ)*func(xi, xj.T)</span><br><span class="line">            b2 = b-Ej-yi*(alpha[i]-preI)*func(xi, xj.T) - \</span><br><span class="line">                yj*(alpha[j]-preJ)*func(xj, xj.T)</span><br><span class="line">            <span class="keyword">if</span> alpha[i] &gt; <span class="number">0</span> <span class="keyword">and</span> alpha[i] &lt; C:</span><br><span class="line">                b = b1</span><br><span class="line">            <span class="keyword">elif</span> alpha[j] &gt; <span class="number">0</span> <span class="keyword">and</span> alpha[j] &lt; C:</span><br><span class="line">                b = b2</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                b = (b1+b2)/<span class="number">2</span></span><br><span class="line">            index.remove(i)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            index.remove(i)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    print(<span class="string">'training: epoch No.'</span>, t)</span><br><span class="line">print(<span class="string">'*** data training finish ***'</span>)</span><br><span class="line"><span class="keyword">return</span> alpha, b</span><br></pre></td></tr></table></figure></p>
<h2 id="数据测试">数据测试</h2>
<p>完成分类器之后，数据测试就变得十分简单。在最开始，我们已经给出了SVM正确分类的充要条件，即条件<span class="math inline">\((1)\)</span>。因此只要将测试集数据输入SVM，判断式<span class="math inline">\((1)\)</span>是否成立即可。以下为数据测试的python代码： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(testData, testLabel, trainData, trainLabel, alpha, b, kernel)</span>:</span></span><br><span class="line">    print(<span class="string">'testing...'</span>)</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(testData, testLabel):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> kernel:</span><br><span class="line">            w = cal_w(x, alpha, trainData, trainLabel)</span><br><span class="line">            predLabel = np.dot(w, x.T)+b</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            predLabel = pred(x, b, alpha, kernel, trainData, trainLabel)</span><br><span class="line">        count += <span class="number">1</span> <span class="keyword">if</span> y*predLabel &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> count/len(testLabel)</span><br></pre></td></tr></table></figure></p>
<p>至此，我们终于完成了一个支持向量机！撒花 ★,°<em>:.☆(￣▽￣)/.</em>.°★*</p>
<hr>
<p>这篇博客从5.28开始，已经过去快半个月了…终终终终于写完啦！（泪流满面</p>
<p><span class="math display">\[2018.6.12\;by \; \mathcal{WHY}\]</span></p>

      
    </div>
    
    
    

    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:</strong>
    why
  </li>
  <li class="post-copyright-link">
    <strong>Post link:</strong>
    <a href="git@github.com:creeper121386/Creeper121386.github.io.git/2018/05/28/AI酱养成计划（四）使用支持向量机！/" title="机器学习（四）使用支持向量机！">git@github.com:creeper121386/Creeper121386.github.io.git/2018/05/28/AI酱养成计划（四）使用支持向量机！/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice: </strong>
    All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/python/" rel="tag"># python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/20/AI酱养成计划（三）多层全连接网络与BP算法/" rel="next" title="机器学习（三）多层全连接网络与BP算法">
                <i class="fa fa-chevron-left"></i> 机器学习（三）多层全连接网络与BP算法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/06/whyの学习笔记-深度视觉识别（from-CS231n）/" rel="prev" title="whyの学习笔记 深度视觉识别（from CS231n & NTU-ML）">
                whyの学习笔记 深度视觉识别（from CS231n & NTU-ML） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNzQ3NS8xNDAwNw=="></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="https://avatars2.githubusercontent.com/u/32115448?s=460&v=4" alt="why">
          <p class="site-author-name" itemprop="name">why</p>
           
              <p class="site-description motion-element" itemprop="description">中国武汉 华中科技大学 联创团队</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">33</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/category/index.html">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">16</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/creeper121386" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://weibo.com/5807408179/profile?topnav=1&wvr=6" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                    
                      Weibo
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:694029828@qq.com" target="_blank" title="E-Mail">
                  
                    <i class="fa fa-fw fa-envelope"></i>
                  
                    
                      E-Mail
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.google.com.hk/" target="_blank" title="Google">
                  
                    <i class="fa fa-fw fa-google"></i>
                  
                    
                      Google
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://unique-ailab.github.io/" title="UniqueAI" target="_blank">UniqueAI</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.hustunique.com/" title="联创团队" target="_blank">联创团队</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://luxiaoxiaodan.github.io/" title="华亭鹤唳" target="_blank">华亭鹤唳</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://jojo.fit/" title="yjxの博客" target="_blank">yjxの博客</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://moecode.com/" title="moecode" target="_blank">moecode</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://alexfan.cn/" title="AlexFan" target="_blank">AlexFan</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://icegrave0391.github.io/" title="zcqの博客" target="_blank">zcqの博客</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#支持向量机svm"><span class="nav-number">1.</span> <span class="nav-text">#4 支持向量机（SVM）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#线性可分问题"><span class="nav-number">1.1.</span> <span class="nav-text">线性可分问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#求解最大分隔超平面"><span class="nav-number">1.2.</span> <span class="nav-text">求解最大分隔超平面</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#函数间隔与几何间隔"><span class="nav-number">1.2.1.</span> <span class="nav-text">函数间隔与几何间隔</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#拉格朗日算子法"><span class="nav-number">1.2.2.</span> <span class="nav-text">拉格朗日算子法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#软间隔与松弛变量"><span class="nav-number">1.2.3.</span> <span class="nav-text">软间隔与松弛变量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#核函数"><span class="nav-number">1.3.</span> <span class="nav-text">核函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#映射到高维空间"><span class="nav-number">1.3.1.</span> <span class="nav-text">映射到高维空间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#核方法"><span class="nav-number">1.3.2.</span> <span class="nav-text">核方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练模型序列最小化优化算法smo"><span class="nav-number">1.4.</span> <span class="nav-text">训练模型：序列最小化优化算法(SMO)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#对偶问题"><span class="nav-number">1.4.1.</span> <span class="nav-text">对偶问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#求解alpha"><span class="nav-number">1.4.2.</span> <span class="nav-text">求解\(\alpha\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启发式方法"><span class="nav-number">1.4.3.</span> <span class="nav-text">启发式方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#alpha_1的选择"><span class="nav-number">1.4.3.1.</span> <span class="nav-text">\(\alpha_1\)的选择</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#alpha_2的选择"><span class="nav-number">1.4.4.</span> <span class="nav-text">\(\alpha_2\)的选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优化alpha_i和alpha_j"><span class="nav-number">1.4.5.</span> <span class="nav-text">优化\(\alpha_i\)和\(\alpha_j\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#求解alpha_2newalpha_1new"><span class="nav-number">1.4.6.</span> <span class="nav-text">求解\(\alpha_2^{new},\alpha_1^{new}\)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据测试"><span class="nav-number">1.5.</span> <span class="nav-text">数据测试</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">why</span>
</div>



<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  

  <div class="bg_content">
  <canvas id="canvas"></canvas>
</div>
<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"live2d-widget-model-koharu"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"tagMode":false});</script></body>
</html>

<script type="text/javascript" src="/js/src/click_why.js"></script>
<script type="text/javascript" src="/js/src/dynamic_bg.js"></script>
